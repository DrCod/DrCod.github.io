---
title: 'The workings of machine learning under the hood'
date: 2020-01-27
permalink: /posts/2020/01/blog-post-1/
---

This tutorial covers the breadth and some depths of machine learning. At the end of this tutorial , I attempt to convey to you my understanding of the objectives that we will cover in this tutorial. 

At the end of this tutorial, you will understand
1. How machine learning works under the hood
2. The different learning processes
3. The most common error functions
4. And decide the which error function is best for your problem
5. The different steps in machine learning optimization using gradient descent
6. The differencess between batch, mini-batch , and online learning

As a new-comer to  machine learning, it appears as if machine learning is  some kind of magic. The bad news is, machine learning is not magic at all. It is entirely about applying mathematical formulations to how we view and understand the human learning process.

The world and everything in it can be modeled with mathematical and statistical formulations. In machine learning, the goal is to learn about such formulations, in order to make valid generalizations from  a limited number of observations. For instance, you do not need to see all the trees in the world to learn to recognise one. And this is because we, humans have learnt to identify and distinguish the unique characteristics of trees. So machine learning, equipped with large amounts of data, and compute power, can learn to perform large number of important human tasks.

## Interpreting learning as an optimization problem

Machine learning algorithms are classified into supervised learning , unsupervised  ,and reinforcement learning  based on their purpose. 

* _Supervised Learning_

In this type of learning, the algorithm learns similarly to  how a student learns from supervision by a teacher.In a classroom, a teacher will provide good examples to the student to memorize(or understand how to recognize), then the student derives general rules from these specific examples. The learning algorithm is fed example data with corressponding target responses that consists of numeric or string labels, such as classes or labels ,in order to predict the correct response when posed with new examples. In machine learning ,two very important and often encourntered problems in this type of learning are – regression and classification. For regression ,the target is numeric whilst in classsification, the target is a class or a label. An example of a regression task is, determining th prices of house in Tamale. A classification tasks distinguishes the different kinds of cassava diseases based on the features of the cassava leaves.

* _Unspervised Learning_

In this type , there is no supervision.The algorithm learns by itself from plain examples without associated target responses. This leaves the algorithm to discover data patterns on its own. This type of algorithm tends to restructure the data into something else, such as new features that may represent a class, for instance. The goal is to get meaningful insights about the data. New data inputs derived this type of algorithm can even be fed into suspervised macine learning algorthnms. Humans learns similarly. We employ a similar technique to figure out that certain objects or events are from the same class by observing their similarity. An example application is an automated youtube recommendation algorithm that suggests you videos you would love to watch, using previous watched videos.

* _Reinforcement Learning_

In tis type of learning, you present the algorithm without any labels, similar to unsupervised learning. But the example you give the algorithm, is associated with a feedback according to the solution the algorithm proposes. Just as we take decisions everyday, each decision bears consequences. If a decision did not go as planned, we get penalized and so we learn to make a better decision next time. It is a kind of trial and error learning. In this type of learning, the algorithm must take a decision and act, although that decision bears some attached consequence such as reward or penalty(cost, loss of time,regret, pain, and so on).
[Find this video](https://www.youtube.com/watch?v=V1eYniJ0Rnk.) of Google DeepMind reinforcement learning program that learns to play the Atari’s video games.


### Learning Process

By far, supervised learning is the most popular and frequently used of the three types. But the common central idea to all machine learning algorithms is that, you can formulate a problem using a mathematical function that the algorithm does not know  in advance, but can guess after having seen some data. So in this section we will delve more into the supervised learning problem formulation and learning process.

The objective of a supervised classifier is to assign a class to  an example , after having observed and examined some characteristics of the example itself. We call these characteristics , features. They can be numeric values or string labels. To correctly assign a class to an example, the classifer must first observe and examine some set of known examples(examples with an assigned class), each example-class pair with the samse kind of features as the examples without the classes. So in the learning phase, the classifier learns from observing many examples , so that It can provide an answer when it sees an example without a class later.

Machine learning classifier works by creating a mathematical formulation that includes all given features in a given way – a way that creates a function that can distinguish one class from the other. Where we consider the mathematical formulation(unknown to the classifier) to be called a target function expressing the characteristics of our input examples,  a mahcine learning classifier can search for its representations – a function that approximately works like the target function. In other words, the classifiers tries to find a function that maps the some set of examples to some set of targets.

During optimization, the algorithm searches amongst the possible variants of parameter combinations inorder to find the best set of parameters that allows the correct mapping between featues and classes during the training phase. The process involves evaluating all possible potential target functions that the algorithm can guess. This set of all potential target functions is called the hypothesis space, and the resulting classifier with all its set parameters is the hypothesis.
As shown in the image below, in order to accurately map back to the target function, the algorithm needs lots of data to extrapolate to.
<br/> <img src="/images/funcaproxy.png" /> <br/>
<cite>Source: Machine Learning for Dummies</cite>

#### Exploring the Cost Functions

What actually drives a machine learning algorithm, is not the data! It the internal function feeding back a response signal to the learning algorithm. This function is called the cost function, aka – loss, scoring function, objective function, or error function. It is this cost function that is to be optimised by your algorithm of choice. The cost function is an evaulation function , thus a function that cross-checks and measures  how well the algorithm maps the the features to the targets via the  target function that it is striving to guess. In other words, a cost function tells how well a machine learning algorithm is performing  in an assigned task such as a supervised learning prediction task or an unsuprvised learning clustering problem.

<br/> <img src="/images/costfunc.png" /><br/>
<cite>Image source: https://i.stack.imgur.com/O752N.png</cite>

The image shown above is a complete machine learning problem formulation with a squared cost function. Commonly used cost functions in supervised learning includes the _squared loss_(used for regression problems), and _hinge loss_(used for classification problems).

In unsupervised learning ,a frequent loss is the _reconstruction loss_ employed in **autoencoders**.

What happens is, it evaluates by comaparing what the algorithm preidicts against what the real world outcome is, by using distance/similarity measure metrics. This comparison aims to quantify the error level of the algorithm. The cost function then transmits what is important to the learning algorithm. So overall, a good cost function formulation should be based on your understanding of the problem you are trying to solve.

 The optimisation process sets the internal parrameters,thus the different variants of parameter combination that your algorithm hypothesizes , in the attempt to approximate the ultimate target function or real world model. However, not all parameters are learnable. Some parameters are not to be learned by the algorithm . We call these , hyperparameters. Their role is to fine-tune the generalisation and robustness of your algorithm to noise and other irregularities in your data. As the algorithm is learning, the cost function changes according to changes in the internal parameters. Those changes most beneficial to the achieving less prediction errors are retained to update the algorithm. Finally,as the algorithm continues  to train, the loss/error calculated from the cost funcitoon improves iteration by iteration. However,when the cost function evaluation is not improving , there are various tricks you can implement to stop the learning process


 ##### Gradient Descent

 <br/> <img src="/images/gradescent.png"/><br/>
 <cite>Source: Machine Learning for Dummies</cite>

 In the optimisation process, you have a global minimum and many local minima, as indicated in the image above. A global minimum is the ultimate solution to an optimisation or learning problem because it produces the least error. Local minima are solutions that seem to produce the minimum error but actually do not. 

Gradient descent algorithm is among a wide array of iterative methods used to search some set of functions in a given space, with the goal of discovering the optimal set of parameters that will minimize some objetive function. With gradient descent, the objective is to find the global minimum solution, which means finding the best generalizable function of parameters and a given feature data matrix,inorder to approximate the target function with minimum error.

A feature data matrix is a vector of feature vectors. The feature vectors are n-dimensional , where <var>n</var> = number of features. Example,what characterises every house can be the number of windows, numbe of doors,price of the house, location of the house, number of rooms, and area of land. This forms a _6_ dimensional feature vector. Now suppose we are considering _5_ instances of houses, then our feature matrix or data matrix is of **_5_ x _6_** dimensions. So generally speaking, suppose that we have <var>m</var> data instances or examples, where each example is a vector of **_1_ x _n_** features,then our feature matrix or data, has the shape of **_m_ x _n_**. We  will dive more into the practical details in our next tutorial.

* **_So how does the gradient algorithm work in machine learning?_**

The gradient descent algorithm works out a solution to an optimization problem(learning task) by starting from a random solution, when given a set of parameters and inputs (data matrix made of features and a target). This random solution is a function which takes random initial parameters, and given feature matrix as input. It then makes several iterations whilst using feedback from the cost function, by changing paramaters that gradually improve( lower error) the random solution it started out with. Truth be told, gradient descent algorithhm iterates several times before eventually raching a good mapping. It does this so well, whilst relying on changes in those internal paramters that improve the target cost function the most( lower error) during each iteration.


###### The End : Mini-batch update

Machine learning boils down to solving an optimization problem. Given more data, a  better solution can be reached after some number of iterations. In machine  learning, and software engineering in general ,resource- time and memory - management is extremely crucial. So, the size of the data becomes a problem , especially if you are streaming data from the internet(in online learning) as this increases the compute complexity and requirements. Some algorithms can work with the core computer memory( when working with data with a size just within the computer memory size). These are called batch-algorithms. However, some other machine larning algorithms can’t fit into this core memory because it requires a large data size. An example is data derived from the web. Others include, data from sensors, tracking devices, satellites,and video monitoring.

So over the past years , several proposed and efficient strategies can be applied to solve this challenge. An example involves subsampling your giant data. Data is reshaped(resized) by selection of instances and sometimes features based on statistical sampling, into a reduced and a more  manageable data matrix. Sometimes this trick does not imporve the algorithm’s performance. However, when well implemented, it gives good and reliable results. 

Statistically, this can be achieved by random or stratified sample drawings. The only chanllenge is that, data with large dimensionality(many examples and many features) is more difficult because it needs much larger samples and so may not even fit into your core memory. Other techniques include  parallel computing where you split the data into mutiple computers(workers) connected together in a network. This idea underpins map-reduce, cluster computer frameworks, apache hadoop, apache spark and other advanced technologies. 

Yet another resource-minimalist approach employs chunking of data. The data is first stored in a disk,then fed into your computer memory, after splitting it into chunks much smaller than the your core computer memory. This feeding process is called streaming. In this way, the algorithm is able to handle the data properly, and use them for updating the machine learning algorithm optimisation. After the update , the computer discards them in favor of a new chunk which the algorithm uses for learning. This process is called mini-batch learning or online learning(for streaming web data). This method , however takes a longer time for optimization as against the batch method. Based on the mini-batch and single-example approach, sometimes  there is a repeated parameter updates. When this happens , gradient descent becomes known as stochastic gradient descent.



###### Further Reading
1. Machine Learning for Dummies by John Paul Mueller & Luca Masaron
2. Artificial Intelligence for Starters ebook by Data Science Nigeria
3. Machine Learning Algorithms and Applications by Mohssen Mohammed,Mohammed Badruddin Khan and Eihab Bashier Mohammed Bashier
4. Introduction to Machine Learning(Coursera) by Andrew Ng
5. [Linear Algebra by Gilbert Strang](https://www.youtube.com/playlist?list=PL49CF3715CB9EF31D)
6. Revisit Calculus(single-variable & multivariable)


**Upcoming Tutorial: _Practical Machine Learning with Python_**
