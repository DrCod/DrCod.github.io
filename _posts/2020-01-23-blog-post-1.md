---
title: 'The workings of machine learning under the hood'
date: 2020-01-27
permalink: /posts/2020/01/blog-post-1/
---

This tutorial covers the breadth and depths of machine learning. At the end of this tutorial , I attempt to convey to you my understanding of the objectives that we will cover in this tutorial. 

At the end of this tutorial, you will understand
1. How machine learning works under the hood
2. The different learning processes
3. The most common error functions
4. And decide the which error function is best for your problem
5. The different steps in machine learning optimization using gradient descent
6. The differencess between batch, mini-batch , and online learning

As a newcomer to  machine learning, it appears as if machine learning is  some kind of magic. The bad news is, machine learning is not magic at all. It is entirely about applying mathematical formulations to how we view and understand the human learning process.

The world and everything in it can be modeled with mathematical and statistical formulations. In machine learning, the goal is to learn about such formulations, in order to make valid generalizations from  a limited number of observations. For instance, you do not need to see all the trees in the world to learn to recognise one. And this is because we, humans have learnt to identify and distinguish the unique characteristics of trees. So machine learning, equipped with large amounts of data, and compute power, can learn to perform large number of important human tasks.

## Interpreting learning as an optimization problem

Machine learning algorithms are classified into supervised learning , unsupervised  ,and reinforcement learning  based on their purpose. 

* _Supervised Learning_

In this type of learning, the algorithm learns similarly to  how a student learn from supervision by a teacher.In a classroom, a teacher will provide good examples to the student to memorize(or understand how to recognize), then the student derives general rules from these specific examples. The learning algorithm is fed example data with corressponding target responses that consists of numeric or string labels, such as classes or labels ,in order to predict the correct response when posed with new examples. In machine learning ,two very important and often encountered problems in this type of learning are – regression and classification. For regression ,the target is numeric whilst in classsification, the target is a class or a label. An example of a regression task is, determining th prices of houses in Tamale. A classification tasks distinguishes the different kinds of cassava diseases based on the features of the cassava leaves.

* _Unspervised Learning_

In this type , there is no supervision.The algorithm learns by itself from plain examples without associated target responses. This leaves the algorithm to discover data patterns on its own. This type of algorithm tends to restructure the data into something else, such as new features that may represent a class, for instance. The goal is to get meaningful insights about the data. New data inputs derived from this type of algorithm can even be fed into supervised machine learning algorithms. Humans learn in a similar fashion. We employ a similar technique to figure out that certain objects or events are from the same class by observing their similarity. An example application is an automated youtube recommendation algorithm that suggests you videos you would love to watch, using previously watched videos.

* _Reinforcement Learning_

In this type of learning, you present the algorithm without any labels, similar to unsupervised learning. But the example you give the algorithm, is associated with a feedback according to the solution the algorithm proposes. Just as we take decisions everyday, each decision bears some consequences. If a decision did not go as planned, we get penalized and so we learn to make a better decision next time. It is a kind of trial and error learning. In this type of learning, the algorithm must take a decision and act, although that decision bears some attached consequence such as reward or penalty(cost, loss of time,regret, pain, and so on).
[Find this video](https://www.youtube.com/watch?v=V1eYniJ0Rnk.) of Google DeepMind reinforcement learning program that learns to play the Atari’s video games.


### Learning Process

By far,from industry applications and personal observations it appears that supervised learning is the most popular and frequently used of the three types. But the common central idea to all machine learning algorithms is that, you can formulate a problem using a mathematical function that the algorithm does not know  in advance, but can guess after having seen some data. So in this section we will delve more into the supervised learning problem formulation and learning process.

The objective of a supervised classifier is to assign a class to  an example , after having observed and examined some characteristics of the example itself. We call these characteristics , features. They can be numeric values or string labels. To correctly assign a class to an example, the classifer must first observe and examine some set of known examples(examples with an assigned class), each example-class pair with the same kind of features as the examples without the classes. So in the learning phase, the classifier learns from observing many examples , so that It can provide an answer when it sees an example without a class later.

Machine learning classifier works by creating a mathematical formulation that includes all given features in a given way – a way that creates a function that can distinguish one class from the other. Where we consider the mathematical formulation(unknown to the classifier) to be called a target function expressing the characteristics of our input examples,  a machine learning classifier can search for its representations – a function that approximately works like the target function. In other words, the classifiers try to find a function that maps some set of examples to some set of targets.

During optimization, the algorithm searches amongst the possible variants of parameter combinations in order to find the best set of parameters that allows the correct mapping between features and classes during the training phase. The process involves evaluating all possible potential target functions that the algorithm can guess. This set of all potential target functions is called the hypothesis space, and the resulting classifier with all its set parameters is the hypothesis.
As shown in the image below, in order to accurately map back to the target function, the algorithm needs lots of data to extrapolate to.
<br/> <img src="/images/funcaproxy.png" /> <br/>
<cite>Source: Machine Learning for Dummies</cite>

### Exploring the Cost Functions

What actually drives a machine learning algorithm, is not the data! It the internal function feeding back a response signal to the learning algorithm. This function is called the cost function, aka – loss, scoring function, objective function, or error function. It is this cost function that is to be optimised by your algorithm of choice. The cost function is an evaulation function , thus a function that cross-checks and measures  how well the algorithm maps the the features to the targets via the  target function that it is striving to guess. It is called a loss/error function if it is to be minimized, and a scoring function if it is to be maximised. In other words, a cost function tells how well a machine learning algorithm is performing  in an assigned task such as a supervised learning prediction task or an unsupervised learning clustering problem.

<br/> <img src="/images/costfunc.png" /><br/>
<cite>Image source: https://i.stack.imgur.com/O752N.png</cite>

The image shown above is a complete machine learning problem formulation with a mean squared cost function. Commonly used cost functions in supervised learning includes the _squared loss_(used for regression problems), and _hinge loss_(used for classification problems).

In unsupervised learning ,a frequent loss is the _reconstruction loss_ employed in **autoencoders**.

What happens is, the cost function evaluates by comparing what the algorithm predicts against what the real world outcome says, by using distance/similarity measure metrics. This comparison aims to quantify the error level of the algorithm. The cost function then transmits what is important to the learning algorithm. So in overall, a good cost function formulation  is critical in machine learning and should be based on your understanding of the problem you are trying to solve.

 The optimization process sets the internal parameters,thus the different variants of parameter combination that your algorithm hypothesizes , in the attempt to approximate the ultimate target function or real world model. However, not all parameters are learnable. Some parameters are not to be learned by the algorithm . We call these , hyperparameters. Their role is to fine-tune the generalization and robustness of your algorithm against noise and perturbations in your data. As the algorithm is learning, the cost function changes according to changes in the internal parameters. Those changes most beneficial to the achieving less prediction errors are retained and used to update the algorithm. Finally,as the algorithm continues  to train, the loss/error calculated from the cost function improves after every iteration. However,when the cost function evaluation is not improving , there are various tricks you can implement to halt the training phase.

  **Gradient Descent**

 <br/> <img src="/images/gradescent.png"/><br/>
 <cite>Source: Machine Learning for Dummies</cite>

 Machine problems takes the shape of convex or non-convex optimization problems. In non-convex optimization ,you have a global minimum and many local minima, as indicated in the image above. However,a convex problem has only one solution which is the global minimum.  A global minimum is the ultimate solution to an optimization problem because it produces the least error. But local minima are solutions that seem to produce the minimum error but actually do not. 

  <br/> <img src="/images/convex.gif"/><br/>
  <cite>Source: https://stats.stackexchange.com/questions/324561/difference-between-convex-and-concave-functions</cite>
  Above is an illustration of a convex function, with only one solution, the global minimum.


The gradient descent algorithm is among a wide array of iterative methods used to search some set of functions in a given space, with the goal of discovering the optimal set of parameters that will minimize some objetive error function.

A feature data matrix is a vector of feature vectors. The feature vectors are n-dimensional , where <var>n</var> = number of features. As an example,what characterises every house can be the number of windows, number of doors,price of the house, location of the house, number of rooms, and area of land. This forms a _6_ dimensional feature vector. Now suppose we are taking _5_ instances of houses, then our feature matrix or data matrix is of **_5_ x _6_** dimensions. So generally speaking, suppose that we have <var>m</var> data instances or examples, where each example is a vector of **_1_ x _n_** features,then our feature matrix or data, has the shape of **_m_ x _n_**. We  will see more of this as we dive more into the practical details in our next tutorial.

* **_So how does the gradient descent algorithm work in machine learning?_**

 <br/> <img src="/images/gradalg.jpeg"/><br/>
 <cite>Source: https://towardsdatascience.com/an-introduction-to-gradient-descent-c9cca5739307</cite>
 An illustration of the gradient descent algorithm.

The gradient descent algorithm works out a solution to an optimization problem(learning task) by starting from a random solution, when given a set of parameters and inputs (data matrix made of features and a target). This random solution is a function which takes random initial parameters, and some given feature matrix as input. Then it makes several iterations whilst using feedback from the cost function. The feedback  is generated from tweaking the paramaters by means of taking the **partial derivative** of the cost function with respect to the parameters. The algorithm will then take some steps -not too large, not too small - called the **learning rate**, in the same direction as the parameters that will move it towards the global minimum solution. As the algorithm solution converges towards a global minimum solution, the errors computed from the error function becomes smaller and smaller, from the the random solution(relatively large error solution) it had started out with. Truth be told, gradient descent algorithm iterates several times before eventually raching a good mapping. It does this so well, whilst relying on changes in those internal parameters that improve the target cost function the most( lower error) during each iteration.


###### The End : Mini-batch update

Machine learning boils down to solving an optimization problem. Given more data, a  better solution can be reached after some number of iterations. In machine  learning, and software engineering in general ,resources -time and memory- management is extremely crucial. So, the size of the data becomes a problem , especially if you are streaming data from the internet(in online learning) as this increases the compute complexity and requirements. Some algorithms can work with the core computer memory( when working with data of size just within the computer memory size). These are called batch-algorithms. However, some other machine larning algorithms can’t fit into this core memory because it requires a large data size. An example is data derived from the web. Others include, data from sensors, tracking devices, satellites,and video monitoring.

So over the past years , several proposed and efficient strategies can be applied to solve this challenge. An example involves subsampling your giant data. Data is reshaped(resized) by selection of instances and sometimes features based on statistical sampling, into a reduced and a more  manageable data matrix. Sometimes this trick does not improve the algorithm’s performance. However, when well implemented, it gives good and reliable results. 

Statistically, this can be achieved by _random or stratified sample_ drawings. The only challenge is that, data with large dimensionality(many examples and many features) is more difficult because it needs much larger samples and so may not even fit into your core memory. Other techniques include  parallel computing where you split the data into mutiple computers(workers) connected together in a network. This idea underpins map-reduce, cluster computer frameworks, apache hadoop, apache spark and other advanced technologies. 

Finally, another resource-minimalistic approach employs chunking of data. The data is first stored in a disk,then fed into your computer memory, after splitting it into chunks much smaller than your core computer memory. This feeding process is called streaming. In this way, the algorithm is able to handle the data properly, and use them for updating the machine learning algorithm optimization. After the update , the computer discards them in favor of a new chunk which the algorithm uses for learning. This process is called mini-batch learning or online learning(for streaming web data). This method , however takes a longer time for optimization as against the batch method. Based on the mini-batch and single-example approach, sometimes  there is a repeated parameter updates due to random sampling of inputs. When this happen, gradient descent becomes, **Stochastic Gradient Descent(SGD)**. [Find more reading on SGD here](https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/)

_Credits to All who took time to thoroughly review my content. Your feedback helped make this content even better. Thank you!_ 


###### Further Reading
1. Machine Learning for Dummies by John Paul Mueller & Luca Masaron
2. Artificial Intelligence for Starters ebook by Data Science Nigeria
3. Machine Learning Algorithms and Applications by Mohssen Mohammed,Mohammed Badruddin Khan and Eihab Bashier Mohammed Bashier
4. Introduction to Machine Learning(Coursera) by Andrew Ng
5. [Linear Algebra by Gilbert Strang](https://www.youtube.com/playlist?list=PL49CF3715CB9EF31D)
6. Read more on Calculus(single-variable & multivariable)


**Upcoming Tutorial: _Practical Machine Learning with Python_**
